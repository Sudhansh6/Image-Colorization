Using cuda device
Epoch 1
-------------------------------
loss: 2.302100	[    0/60000]
loss: 2.300294	[ 6000/60000]
loss: 2.297289	[12000/60000]
loss: 2.301380	[18000/60000]
loss: 2.293710	[24000/60000]
loss: 2.502281	[30000/60000]
loss: 1.591601	[36000/60000]
loss: 2.205169	[42000/60000]
loss: 1.550155	[48000/60000]
loss: 1.496382	[54000/60000]
17054.0 60000
Test Error: 
 Accuracy: 74.5%, Avg loss: 0.013305 

Epoch 2
-------------------------------
loss: 0.819928	[    0/60000]
loss: 0.305984	[ 6000/60000]
loss: 0.185629	[12000/60000]
loss: 0.327551	[18000/60000]
loss: 0.160391	[24000/60000]
loss: 0.257339	[30000/60000]
loss: 0.103205	[36000/60000]
loss: 0.194318	[42000/60000]
loss: 0.071764	[48000/60000]
loss: 0.036649	[54000/60000]
55183.0 60000
Test Error: 
 Accuracy: 97.4%, Avg loss: 0.001415 

Epoch 3
-------------------------------
loss: 0.075325	[    0/60000]
loss: 0.015318	[ 6000/60000]
loss: 0.023106	[12000/60000]
loss: 0.017907	[18000/60000]
loss: 0.032763	[24000/60000]
loss: 0.171125	[30000/60000]
loss: 0.092727	[36000/60000]
loss: 0.033464	[42000/60000]
loss: 0.043378	[48000/60000]
loss: 0.019246	[54000/60000]
58952.0 60000
Test Error: 
 Accuracy: 98.5%, Avg loss: 0.000887 

Epoch 4
-------------------------------
loss: 0.015427	[    0/60000]
loss: 0.005644	[ 6000/60000]
loss: 0.016576	[12000/60000]
loss: 0.015726	[18000/60000]
loss: 0.015217	[24000/60000]
loss: 0.150303	[30000/60000]
loss: 0.102210	[36000/60000]
loss: 0.031287	[42000/60000]
loss: 0.015669	[48000/60000]
loss: 0.035598	[54000/60000]
59266.0 60000
Test Error: 
 Accuracy: 98.6%, Avg loss: 0.000825 

Epoch 5
-------------------------------
loss: 0.016136	[    0/60000]
loss: 0.008711	[ 6000/60000]
loss: 0.019482	[12000/60000]
loss: 0.018407	[18000/60000]
loss: 0.062668	[24000/60000]
loss: 0.068925	[30000/60000]
loss: 0.016767	[36000/60000]
loss: 0.051203	[42000/60000]
loss: 0.005910	[48000/60000]
loss: 0.018240	[54000/60000]
59483.0 60000
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.000625 

Epoch 6
-------------------------------
loss: 0.008918	[    0/60000]
loss: 0.007183	[ 6000/60000]
loss: 0.004317	[12000/60000]
loss: 0.009308	[18000/60000]
loss: 0.005327	[24000/60000]
loss: 0.034787	[30000/60000]
loss: 0.017546	[36000/60000]
loss: 0.004836	[42000/60000]
loss: 0.002493	[48000/60000]
loss: 0.021297	[54000/60000]
59579.0 60000
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.000613 

Epoch 7
-------------------------------
loss: 0.012806	[    0/60000]
loss: 0.001904	[ 6000/60000]
loss: 0.001580	[12000/60000]
loss: 0.050965	[18000/60000]
loss: 0.008398	[24000/60000]
loss: 0.008539	[30000/60000]
loss: 0.093756	[36000/60000]
loss: 0.003052	[42000/60000]
loss: 0.004025	[48000/60000]
loss: 0.013779	[54000/60000]
59659.0 60000
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.000554 

Epoch 8
-------------------------------
loss: 0.003046	[    0/60000]
loss: 0.003074	[ 6000/60000]
loss: 0.005458	[12000/60000]
loss: 0.023620	[18000/60000]
loss: 0.104669	[24000/60000]
loss: 0.001627	[30000/60000]
loss: 0.019577	[36000/60000]
loss: 0.013137	[42000/60000]
loss: 0.011813	[48000/60000]
loss: 0.012841	[54000/60000]
59696.0 60000
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.000652 

Epoch 9
-------------------------------
loss: 0.002953	[    0/60000]
loss: 0.002480	[ 6000/60000]
loss: 0.002655	[12000/60000]
loss: 0.034382	[18000/60000]
loss: 0.009431	[24000/60000]
loss: 0.032491	[30000/60000]
loss: 0.002561	[36000/60000]
loss: 0.023603	[42000/60000]
loss: 0.012178	[48000/60000]
loss: 0.006409	[54000/60000]
59700.0 60000
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.000684 

Epoch 10
-------------------------------
loss: 0.008495	[    0/60000]
loss: 0.004025	[ 6000/60000]
loss: 0.020755	[12000/60000]
loss: 0.028459	[18000/60000]
loss: 0.003280	[24000/60000]
loss: 0.014435	[30000/60000]
loss: 0.033417	[36000/60000]
loss: 0.043392	[42000/60000]
loss: 0.060515	[48000/60000]
loss: 0.003706	[54000/60000]
59738.0 60000
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.000624 

Epoch 11
-------------------------------
loss: 0.007845	[    0/60000]
loss: 0.015349	[ 6000/60000]
loss: 0.002978	[12000/60000]
loss: 0.048700	[18000/60000]
loss: 0.007733	[24000/60000]
loss: 0.002919	[30000/60000]
loss: 0.002900	[36000/60000]
loss: 0.001346	[42000/60000]
loss: 0.003979	[48000/60000]
loss: 0.014185	[54000/60000]
59759.0 60000
Test Error: 
 Accuracy: 99.1%, Avg loss: 0.000510 

Epoch 12
-------------------------------
loss: 0.004881	[    0/60000]
loss: 0.006920	[ 6000/60000]
loss: 0.004688	[12000/60000]
loss: 0.009078	[18000/60000]
loss: 0.000707	[24000/60000]
loss: 0.009229	[30000/60000]
loss: 0.011933	[36000/60000]
loss: 0.006605	[42000/60000]
loss: 0.014632	[48000/60000]
loss: 0.001428	[54000/60000]
59825.0 60000
Test Error: 
 Accuracy: 98.9%, Avg loss: 0.000647 

Epoch 13
-------------------------------
loss: 0.001559	[    0/60000]
loss: 0.003468	[ 6000/60000]
loss: 0.001229	[12000/60000]
loss: 0.008002	[18000/60000]
loss: 0.001275	[24000/60000]
loss: 0.001020	[30000/60000]
loss: 0.005929	[36000/60000]
loss: 0.005721	[42000/60000]
loss: 0.000978	[48000/60000]
loss: 0.014314	[54000/60000]
59812.0 60000
Test Error: 
 Accuracy: 98.8%, Avg loss: 0.000773 

Epoch 14
-------------------------------
loss: 0.047429	[    0/60000]
loss: 0.000682	[ 6000/60000]
loss: 0.001710	[12000/60000]
loss: 0.002944	[18000/60000]
loss: 0.020368	[24000/60000]
loss: 0.026610	[30000/60000]
loss: 0.005234	[36000/60000]
loss: 0.001539	[42000/60000]
loss: 0.004338	[48000/60000]
loss: 0.003401	[54000/60000]
59854.0 60000
Test Error: 
 Accuracy: 99.2%, Avg loss: 0.000545 

Epoch 15
-------------------------------
loss: 0.001009	[    0/60000]
loss: 0.003669	[ 6000/60000]
loss: 0.030860	[12000/60000]
loss: 0.011159	[18000/60000]
loss: 0.001534	[24000/60000]
loss: 0.001674	[30000/60000]
loss: 0.003636	[36000/60000]
loss: 0.001681	[42000/60000]
loss: 0.001209	[48000/60000]
loss: 0.000553	[54000/60000]
59835.0 60000
Test Error: 
 Accuracy: 99.0%, Avg loss: 0.000625 

Done!
[28.423333333333332, 91.97166666666666, 98.25333333333333, 98.77666666666667, 99.13833333333334, 99.29833333333333, 99.43166666666667, 99.49333333333334, 99.5, 99.56333333333333, 99.59833333333333, 99.70833333333333, 99.68666666666667, 99.75666666666666, 99.725]

Saved PyTorch Model State to model.pth
